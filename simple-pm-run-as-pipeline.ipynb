{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "The goal of this notebook is to show how running a notebook via `papermill` as a **AzureML pipeline** differs from using a `ScriptRunConfig`. To see the examples for `ScriptRunConfig`, please see this [notebook](simple-pm-run.ipynb). \n",
    "\n",
    "This notebook assumes [simple-pm-run.ipynb](simple-pm-run.ipynb) has already been run to create resources such as the configuration for your AzureML workspace and your compute target.\n",
    "\n",
    "This notebook started as a copy of the Pipelines Getting Started Notebook [here](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-getting-started.ipynb).\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "This notebook requires that `azureml-sdk` is installed in the environment in which it is run.\n",
    "\n",
    "## Workload\n",
    "\n",
    "This notebook will submit the `papermill_run_notebook.py` script in the `./projectDir` directory, which will, in turn, execute the `hello_world.ipynb` notebook (also in the `./projectDir` directory). It does this by defining the entry script as a `PythonScriptStep()` in a pipeline, and submitting the pipeline. The notebook shows how to do this multiple times after changing various files to show the effects of parameters `hash_paths` and `regenerate_outputs`.\n",
    "\n",
    "This entry script (`papermill_run_notebook.py`) is intended as a simplified version of the one used in the [Microsoft/Recommenders repository](https://github.com/Microsoft/Recommenders/blob/jumin/dnn/reco_utils/aml/wide_deep.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Machine Learning Imports\n",
    "\n",
    "In this first code cell, we import key Azure Machine Learning modules that we will use below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.runconfig import CondaDependencies, RunConfiguration\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "## load pipeline dependencies\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Workspace\n",
    "\n",
    "Initialize a [workspace](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace(class%29) object from persisted configuration, or get it from Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aml_compute_target = \"aml-compute-d2\" ## 2-16 characters\n",
    "exp_name = 'papermill-in-a-pipeline'\n",
    "# project folder\n",
    "project_folder = './projectDir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('aml_config'):\n",
    "    print('Loading Workspace information from configuration')\n",
    "    ws = Workspace.from_config()\n",
    "else:\n",
    "    print('Getting Workspace information from Variables. You must set these or this will fail!')\n",
    "    SUBSCRIPTION_ID = os.getenv(\"AZ_SUB\",\"\")\n",
    "    RESOURCE_GROUP = os.getenv(\"RESOURCE_GROUP\",\"\")\n",
    "    WS_NAME = os.getenv(\"WS_NAME\",\"\")\n",
    "    WS_LOCATION = 'eastus'\n",
    "    ws=Workspace.get(name=WS_NAME,\n",
    "                    resource_group=RESOURCE_GROUP,\n",
    "                    subscription_id=SUBSCRIPTION_ID)\n",
    "\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Targets\n",
    "\n",
    "We will pick up from the prior notebook and focus on cloud computing, and in this case, we'll continue to use AmlCompute for executing our pipeline step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Compute Targets on the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = ws.compute_targets\n",
    "for ct in cts:\n",
    "    print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## run_config.load() does not seem to work:\n",
    "# my_aml_run_config = RunConfiguration()\n",
    "# my_aml_run_config.load(path='.', name=aml_compute_target)\n",
    "# print(my_aml_run_config.target) ## still prints 'local'\n",
    "# it does not load the values...\n",
    "\n",
    "## so recreate\n",
    "aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "\n",
    "cd = CondaDependencies.create(pip_packages=[\"ipykernel\", \"papermill\", \"azureml-sdk\"])\n",
    "my_aml_run_config = RunConfiguration(conda_dependencies=cd)\n",
    "my_aml_run_config.target = aml_compute_target\n",
    "my_aml_run_config.environment.docker.enabled = True\n",
    "my_aml_run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as a Pipeline ...\n",
    "\n",
    "You would create a `PythonScriptStep`, and then a pipeline, and then submit the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses default values for PythonScriptStep construct.\n",
    "\n",
    "step1nohash = PythonScriptStep(name=\"Use papermill to run a notebook\",\n",
    "                         script_name=\"papermill_run_notebook.py\", \n",
    "                         compute_target=aml_compute, \n",
    "                         source_directory=project_folder,\n",
    "                         runconfig=my_aml_run_config,\n",
    "                         allow_reuse=False\n",
    "                        )\n",
    "print(\"Step1 created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build, Validate, and Submit the pipeline\n",
    "You have the option to [validate](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py#validate) the pipeline prior to submitting for run. The platform runs validation steps such as checking for circular dependencies and parameter checks etc. even if you do not explicitly call validate method.\n",
    "\n",
    "### Submit the pipeline\n",
    "[Submitting](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py#submit) the pipeline involves creating an [Experiment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment?view=azure-ml-py) object and providing the built pipeline for submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline(workspace=ws, steps=[step1nohash])\n",
    "print (\"Pipeline is built\")\n",
    "pipeline1.validate()\n",
    "print(\"Pipeline validation complete\")\n",
    "pipeline_run1 = Experiment(ws, exp_name).submit(pipeline1)\n",
    "print(\"Pipeline is submitted for execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for file changes\n",
    "\n",
    "Pipelines are different than experiments. Try editing `msg` in `hello_world.ipynb`, and then building and running the same pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edit `msg` first!!\n",
    "step1nohash = PythonScriptStep(name=\"Use papermill to run a notebook\",\n",
    "                         script_name=\"papermill_run_notebook.py\", \n",
    "                         compute_target=aml_compute, \n",
    "                         source_directory=project_folder,\n",
    "                         runconfig=my_aml_run_config,\n",
    "                         allow_reuse=False\n",
    "                        )\n",
    "print(\"Step1 created\")\n",
    "pipeline1 = Pipeline(workspace=ws, steps=[step1nohash])\n",
    "print (\"Pipeline is built\")\n",
    "pipeline1.validate()\n",
    "print(\"Pipeline validation complete\")\n",
    "pipeline_run1 = Experiment(ws, exp_name).submit(pipeline1)\n",
    "print(\"Pipeline is submitted for execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of Experiments\n",
    "\n",
    "Across runs, you can try changing various things. The table below documents an example set of runs. \n",
    "\n",
    "Entries are bolded if they are different from the entry in the prior row.\n",
    "\n",
    "Column1 corresponds to the run number, column 2 corresponds to what steps I did to the pipeline after I changed a file, column3 corresponds to the value of the `msg` variable in the **notebook**, columng 4 correponds to the value of the `msg2` variable in teh **script**, and columns 5 and 6 correspond to what gets logged by the logger in each run. \n",
    "\n",
    "If you experiment and try various different changes (e.g. only change the notebook, but don't change the script), then you see that by default, with no additional parameters passed, updates to the notebook are only prpagated if you also update the script (and at least rebuild the pipeline). \n",
    "\n",
    "Updating the script triggers an update of the entire source_dir. It doesn't matter if you rebuild the pipeline, or even rebuild the `PythonScriptStep` - if you only update the notebook, you won't see new results. The key rows that show this are runs 5, 7, 8, 11, and 12. Rows 6, 9, and 13 show clearly that both the notebook and the script get updated when the script is changed.\n",
    "\n",
    "\n",
    "\n",
    "| run num |  pipeline updates              | msg status (nb)  | msg2 status (script) | msg log    | msg2 log |\n",
    "|---------|--------------------------------|-------------------|----------------------|------------|----------|\n",
    "| run 1   |  clean                         | hello world           | run1 | hello world     | run1      |\n",
    "| run 2   | **only Experiment.submit()** | hello world           | **run2** | hello world     | run1  |\n",
    "| run 3   | **built, validated, and submited** | hello world           | run2  | hello world     | **run2** |\n",
    "| run 4   | built, validated, and submited | hello world           | **run4**  | hello world     | **run4**  |\n",
    "| run 5   | built, validated, and submited | **'tst 2 - hello world'** | run4  | 'hello world'   | run4  |\n",
    "| run 6   | built, validated, and submited | **'change - hello world'**  | **run7** | **'change - hello world'**  | **run7** |\n",
    "| run 7   | built, validated, and submited | **'chng 2 - hello world'**  | run7 | 'change - hello world'  | run7 |\n",
    "| run 8   | built, validated, and submited | **'hello world'**  | run7 | 'change - hello world'  | run7 |\n",
    "| run 9   | built, validated, and submited | 'hello world'      | **run9** | **'hello world'**  | **run9** |\n",
    "| run 10  | **step def., built, validated, and submited** | 'hello world'      | **run10** | 'hello world'  | **run10** |\n",
    "| run 11  | step def., built, validated, and submited | **'delta: hello world'**      | run10 | 'hello world'  | run10 |\n",
    "| run 12  | step def., built, validated, and submited | **'no show: hello world'**      | run10 | 'hello world'  | run10 |\n",
    "| run 13  | step def., built, validated, and submited | 'no show: hello world'      | **run13** | **'no show: hello world'**  | **run13** |\n",
    "\n",
    "\n",
    "### How to change this behavior\n",
    "\n",
    "There are (at least) two ways to change this behavior.\n",
    "\n",
    "- Use the `hash_paths` argument to `PythonScriptStep()` in order to make sure that key files (like the notebook) are checked for changes prior to submission.\n",
    "- set `regenerate_outputs=True` when you run `Experiment.submit()`.\n",
    "\n",
    "To see these two options in action, see the following sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using hash_paths\n",
    "\n",
    "Reset the hello_world notebook, and rebuild the `PythonScriptStep` and pipeline by defining that file's path as a `hash_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses default values for PythonScriptStep construct.\n",
    "step1withhash = PythonScriptStep(name=\"Use papermill to run a notebook\",\n",
    "                         script_name=\"papermill_run_notebook.py\", \n",
    "                         compute_target=aml_compute, \n",
    "                         source_directory=project_folder,\n",
    "                         runconfig=my_aml_run_config,\n",
    "                         allow_reuse=False,\n",
    "                         hash_paths=['hello_world.ipynb']\n",
    "                        )\n",
    "print(\"Step1 created\")\n",
    "pipeline1 = Pipeline(workspace=ws, steps=[step1withhash])\n",
    "print (\"Pipeline is built\")\n",
    "pipeline1.validate()\n",
    "print(\"Pipeline validation complete\")\n",
    "pipeline_run1 = Experiment(ws, exp_name).submit(pipeline1)\n",
    "print(\"Pipeline is submitted for execution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now change various features in the files and notebooks similar to above, and resbumit\n",
    "\n",
    "pipeline1 = Pipeline(workspace=ws, steps=[step1withhash])\n",
    "print (\"Pipeline is built\")\n",
    "pipeline1.validate()\n",
    "print(\"Pipeline validation complete\")\n",
    "pipeline_run1 = Experiment(ws, exp_name).submit(pipeline1)\n",
    "print(\"Pipeline is submitted for execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of Experiments with hash_paths\n",
    "\n",
    "This table has similar rows and colums as the one above. The only difference in these pipeline runs is that, within the `PythonScriptStep`, `hash_paths=['hello_world.ipynb']`. With that additional argument, you see very different behavior. Output of each pipeline run tracks changes when either script or notebook changes.\n",
    "\n",
    "| run num |  pipeline updates              | msg status (nb)  | msg2 status (script) | msg log    | msg2 log |\n",
    "|---------|--------------------------------|-------------------|----------------------|------------|----------|\n",
    "| run 1   |  clean                         | hello world           | run1 | hello world     | run1      |\n",
    "| run 2   | **Experiment.submit()**        | hello world           | **run2** | hello world     | run1  |\n",
    "| run 3   | **built, validated, and submited** | hello world           | run2  | hello world     | **run2** |\n",
    "| run 4   | built, validated, and submited | hello world           | **run4**  | hello world     | **run4**  |\n",
    "| run 5   | built, validated, and submited | **'chng: Hello World!'** | run4  | **'chng: Hello World!'**  | run4  |\n",
    "| run 6   | built, validated, and submited | **'Hello World again!'** | run4  | **'Hello World again!'**  | run4  |\n",
    "| run 7   | **step def., built, validated, and submited** | 'Hello World again!'   | run4 | 'Hello World again!'  | run4 |\n",
    "| run 8    | step def., built, validated, and submited | **'Hello World!'**      | run4 | **'Hello World!'**  | run4 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore regenerate_outputs\n",
    "\n",
    "We can try the same experiment (this time with `hash_paths=None`) to see if the `regenerate_outputs` parameter in `Experiment.submit()` has a similar effect. \n",
    "\n",
    "In this case, because we know that script changes trigger an update, we'll just manipulate the notebook, the pipeline upates, and whether regenerate_outputs is true or false on the submit call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edit `msg` first!!\n",
    "step1nohash = PythonScriptStep(name=\"Use papermill to run a notebook\",\n",
    "                         script_name=\"papermill_run_notebook.py\", \n",
    "                         compute_target=aml_compute, \n",
    "                         source_directory=project_folder,\n",
    "                         runconfig=my_aml_run_config,\n",
    "                         allow_reuse=False\n",
    "                        )\n",
    "print(\"Step1 created\")\n",
    "pipeline1 = Pipeline(workspace=ws, steps=[step1nohash])\n",
    "print (\"Pipeline is built\")\n",
    "pipeline1.validate()\n",
    "print(\"Pipeline validation complete\")\n",
    "pipeline_run1 = Experiment(ws, exp_name).submit(pipeline1, regenerate_outputs=False)\n",
    "print(\"Pipeline is submitted for execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try changing the notebook, the value of regnereate_outputs, and rerunning\n",
    "pipeline1 = Pipeline(workspace=ws, steps=[step1nohash])\n",
    "print (\"Pipeline is built\")\n",
    "pipeline1.validate()\n",
    "print(\"Pipeline validation complete\")\n",
    "pipeline_run1 = Experiment(ws, exp_name).submit(pipeline1, regenerate_outputs=True)\n",
    "print(\"Pipeline is submitted for execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of Experiments with regenerate_outputs\n",
    "\n",
    "In all cases, `hash_paths=None`.\n",
    "\n",
    "This table is similar to the tables above, but now column 2 reflects teh value of the regenerate_outputs parameter.\n",
    "\n",
    "`regenerate_outputs` enforces a new build. Not passing it as an argument seems analogous to `regenerate_outputs=False`, but it appears undocumented. If `regnerate_outputs==False`, then changes to the notebook do not get propagated. to the run. If `regenerate_outputs==True`, then changes to the notebook are propagated.\n",
    "\n",
    "\n",
    "| run num |  regenerate_outputs | pipeline updates | msg status (nb)  | msg2 status (script) | msg log    | msg2 log |\n",
    "|---------|---------------------|-----------|-------------------|----------------------|------------|----------|\n",
    "| run 1   | 0 | clean                         | hello world           | run1 | hello world     | run1      |\n",
    "| run 2   | 0 | **Experiment.submit()**        | **tst2**          | run1 | hello world     | run1  |\n",
    "| run 3   | **1** | Experiment.submit()        | tst2          | run1 | hello world     | run1  |\n",
    "| run 4   | 1 | Experiment.submit()        | tst2          | **run4** | hello world     | run1  |\n",
    "| run 5   | 1 | **built, validated, and submited** | tst2           | **run1**  | **tst2**     | run1 |\n",
    "| run 6   | 1 | built, validated, and submited | **change**           | run1  | **change**     | run1 |\n",
    "| run 7   | 1 | built, validated, and submited | change           | run1  | change     | run1 |\n",
    "| run 8   | 1 | built, validated, and submited | **delta**           | run1  | **delta**     | run1 |\n",
    "| run 9   | 1 | built, validated, and submited | **gamma**           | run1  | **gamma**     | run1 |\n",
    "| run 10   | **0** | built, validated, and submited | **epsilon**           | run1  | gamma     | run1 |\n",
    "| run 11   | 0 | built, validated, and submited | **alpha**           | run1  | gamma     | run1 |\n",
    "| run 12   | **1** | built, validated, and submited | alpha           | run1  | **alpha**   | run1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edit `msg` first!!\n",
    "pipeline1 = Pipeline(workspace=ws, steps=[step1])\n",
    "print (\"Pipeline is built\")\n",
    "pipeline1.validate()\n",
    "print(\"Pipeline validation complete\")\n",
    "pipeline_run1 = Experiment(ws, exp_name).submit(pipeline1, regenerate_outputs=False)\n",
    "print(\"Pipeline is submitted for execution\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If regenerate_outputs is set to True, a new submit will always force generation of all step outputs, and disallow data reuse for any step of this run. Once this run is complete, however, subsequent runs may reuse the results of this run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the pipeline run\n",
    "\n",
    "#### Use RunDetails Widget\n",
    "We are going to use the RunDetails widget to examine the run of the pipeline. You can click each row below to get more details on the step runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_runs = pipeline_run1.get_children()\n",
    "for step_run in step_runs:\n",
    "    status = step_run.get_status()\n",
    "    print('Script:', step_run.name, 'status:', status)\n",
    "    \n",
    "    # Change this if you want to see details even if the Step has succeeded.\n",
    "    joblog = step_run.get_job_log()\n",
    "    print('job log:', joblog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step_run"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "diray"
   }
  ],
  "kernelspec": {
   "display_name": "Python [conda env:pm_simple]",
   "language": "python",
   "name": "conda-env-pm_simple-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
