{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "The goal of this is to use `Experiment.submit()` to run a simple script that calls a jupyter notebook. In a second [notebook](simple-pm-run-as-pipeline.ipynb), I show how to set up a pipeline to do this and how it differs in its behavior.\n",
    "\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "This notebook requires that `azureml-sdk` is installed in the environment in which it is run.\n",
    "\n",
    "## Workload\n",
    "\n",
    "This notebook will submit the `papermill_run_notebook.py` script in the `./projectDir` directory, which will, in turn, execute the `hello_world.ipynb` notebook (also in the `./projectDir` directory).\n",
    "\n",
    "This entry script (`papermill_run_notebook.py`) is intended as a simplified version of the one used in the [Microsoft/Recommenders repository](https://github.com/Microsoft/Recommenders/blob/jumin/dnn/reco_utils/aml/wide_deep.py), so that I can document and test effects of parameters in the second [notebook](simple-pm-run-as-pipeline.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Machine Learning Imports\n",
    "\n",
    "In this first code cell, we import key Azure Machine Learning modules that we will use below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Run, Experiment\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.runconfig import CondaDependencies, RunConfiguration\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Workspace\n",
    "\n",
    "Initialize a [workspace](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace(class%29) object from persisted configuration, or get it from Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aml_compute_target = \"aml-compute-d2\" ## 2-16 characters\n",
    "exp_name = 'papermill-as-exp-run'\n",
    "# project folder\n",
    "project_folder = './projectDir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('aml_config'):\n",
    "    print('Loading Workspace information from configuration')\n",
    "    ws = Workspace.from_config()\n",
    "else:\n",
    "    print('Getting Workspace information from Variables. You must set these or this will fail!')\n",
    "    SUBSCRIPTION_ID = os.getenv(\"AZ_SUB\",\"\")\n",
    "    RESOURCE_GROUP = os.getenv(\"RESOURCE_GROUP\",\"\")\n",
    "    WS_NAME = os.getenv(\"WS_NAME\",\"\")\n",
    "    WS_LOCATION = 'eastus'\n",
    "    ws=Workspace.get(name=WS_NAME,\n",
    "                    resource_group=RESOURCE_GROUP,\n",
    "                    subscription_id=SUBSCRIPTION_ID)\n",
    "\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Targets\n",
    "A compute target specifies where to execute your program such as a local environment, a remote Docker on a VM, or a cluster. A compute target needs to be addressable and accessible by you.\n",
    "\n",
    "We will walk through a few examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Compute - User managed\n",
    "\n",
    "The simplest compute corresponds to a python executable in which you already have dependencies created. In this example, \n",
    "we will use a conda environment that was created from the `papermill_conda.yml` file on the local machine. If you need to, you can create the conda environment with:\n",
    "\n",
    "```\n",
    "conda env create -f papermill_conda.yml\n",
    "```\n",
    "\n",
    "Then, update the path to executable with the location of python within that environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_run_config_user_managed = RunConfiguration()\n",
    "local_run_config_user_managed.environment.python.user_managed_dependencies = True\n",
    "local_run_config_user_managed.environment.python.interpreter_path = 'C:\\\\Users\\\\jeremr\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\pm_simple\\\\python.exe'\n",
    "\n",
    "# local_run_config.environment.docker.enabled = False\n",
    "# local_run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as a single submission of an experiment\n",
    "\n",
    "Simply create a `ScriptRunConfig`, then `Experiment.submit()` it to the local, user-managed configuration.\n",
    "\n",
    "In this example, `source_directory` is the directory containing the script to execute the notebook, the notebook, and any other dependencies. All files in this directory get mounted to the container in AmlCompute.\n",
    "\n",
    "The `script` parameter refers to the path to the script you want to run, relative to the root of `source_directory`, and `run_config` is the run configuration you just created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can just run it as an experiment locally\n",
    "my_config = ScriptRunConfig(source_directory=project_folder, \n",
    "                            script='papermill_run_notebook.py', \n",
    "                            run_config=local_run_config_user_managed\n",
    "                            )\n",
    "## submit it...\n",
    "Experiment(ws, exp_name).submit(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run again (still locally), with different parameters passed to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify arguments:\n",
    "argumentlist = [\"-x\", 2, \"-y\", 3]\n",
    "## pass the arguments:\n",
    "my_config = ScriptRunConfig(source_directory=project_folder, \n",
    "                            script='papermill_run_notebook.py', \n",
    "                            run_config=local_run_config_user_managed,\n",
    "                            arguments=argumentlist\n",
    "                            )\n",
    "## submit it...\n",
    "Experiment(ws, exp_name).submit(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use local docker environment\n",
    "\n",
    "Create a new RunConfiguration and change a few values.\n",
    "\n",
    "**NOTE**: This requires that docker is installed and running on the host machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## need ipykernel so that there is a kernel installed.\n",
    "## need azureml-sdk for logging metrics\n",
    "cd = CondaDependencies.create(pip_packages=[\"ipykernel\", \"papermill\", \"azureml-sdk\"])\n",
    "\n",
    "my_local_docker_run_config = RunConfiguration(conda_dependencies=cd)\n",
    "my_local_docker_run_config.environment.docker.enabled = True\n",
    "my_local_docker_run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "my_local_docker_run_config.auto_prepare_environment = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run in Local docker\n",
    "argumentlist = [\"-x\", 2, \"-y\", 3]\n",
    "my_config = ScriptRunConfig(source_directory=project_folder, \n",
    "                            script='papermill_run_notebook.py', \n",
    "                            run_config=my_local_docker_run_config,\n",
    "                            arguments=argumentlist\n",
    "                            )\n",
    "## submit it...\n",
    "Experiment(ws, exp_name).submit(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use AmlCompute\n",
    "\n",
    "First, list the Azure-based computes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Compute Targets on the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = ws.compute_targets\n",
    "for ct in cts:\n",
    "    print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve or create a Azure Machine Learning compute\n",
    "Azure Machine Learning Compute is a service for provisioning and managing clusters of Azure virtual machines for running machine learning workloads. Let's create a new Azure Machine Learning Compute in the current workspace, if it doesn't already exist. We will then run the training script on this compute target.\n",
    "\n",
    "If we could not find the compute with the given name in the previous cell, then we will create a new compute here. We will create an Azure Machine Learning Compute containing **STANDARD_D2_V2 CPU VMs**. This process is broken down into the following steps:\n",
    "\n",
    "1. Create the configuration\n",
    "2. Create the Azure Machine Learning compute\n",
    "\n",
    "**This process will take about 3 minutes and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"found existing compute target.\")\n",
    "except:\n",
    "    print(\"creating new compute target\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1, \n",
    "                                                                max_nodes = 4)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "print(\"Azure Machine Learning Compute attached\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a New AmlCompute RunConfiguration\n",
    "\n",
    "The only real change from local docker is that you need to fill the `target` field with the `aml_compute.name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_aml_run_config = RunConfiguration(conda_dependencies=cd)\n",
    "my_aml_run_config.target = aml_compute.name\n",
    "my_aml_run_config.environment.docker.enabled = True\n",
    "my_aml_run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the same script against AmlCompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run in AmlCompute\n",
    "argumentlist = [\"-x\", 3, \"-y\", 3]\n",
    "my_config = ScriptRunConfig(source_directory=project_folder, \n",
    "                            script='papermill_run_notebook.py', \n",
    "                            run_config=my_aml_run_config,\n",
    "                            arguments=argumentlist\n",
    "                            )\n",
    "## submit it...\n",
    "Experiment(ws, exp_name).submit(my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pass the arguments, and then run across multiple run_configs\n",
    "argumentlist = [\"-x\", 2, \"-y\", 2]\n",
    "run_configs = [my_local_docker_run_config, local_run_config_user_managed, my_aml_run_config]\n",
    "for rc in run_configs:\n",
    "    my_config = ScriptRunConfig(source_directory=project_folder, \n",
    "                            script='papermill_run_notebook.py', \n",
    "                            run_config=rc,\n",
    "                            arguments=argumentlist\n",
    "                            )\n",
    "    ## submit it...\n",
    "    Experiment(ws, exp_name).submit(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the runconfig for AmlCompute to use in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this will save a file to ./aml_config/<aml_compute.name>.runconfig\n",
    "my_aml_run_config.save(path='.', name=aml_compute.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "diray"
   }
  ],
  "kernelspec": {
   "display_name": "Python [conda env:pm_simple]",
   "language": "python",
   "name": "conda-env-pm_simple-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
